{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyO5uzXc2v/+yOMg5WrJr9i3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mmostafahareb/credential_finder/blob/main/Transformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imports:"
      ],
      "metadata": {
        "id": "s7pZonyCaykn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.layers import GlobalAveragePooling1D\n"
      ],
      "metadata": {
        "id": "u7CAxaV_ag0_"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Extracting and Labeling"
      ],
      "metadata": {
        "id": "WE8-e6zZagCw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pvAlC4ZUKCnM",
        "outputId": "81e2e5e6-3c14-4b37-bed2-78c197680af4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Projects/Clean/main2.js', 'Projects/Clean/detect_make.py', 'Projects/Clean/Styled.tsx', 'Projects/Clean/index-1 (3).js', 'Projects/Clean/views.py', 'Projects/Clean/insertion_sort.py', 'Projects/Clean/acronym_generator.py', 'Projects/Clean/ClientHandler.java', 'Projects/Clean/Text_layout.js', 'Projects/Clean/Templatable.js', 'Projects/Clean/parse_pom.js', 'Projects/Clean/TaskRunner.js', 'Projects/Clean/indexing.py', 'Projects/Clean/euclid_gcd.py', 'Projects/Clean/SimilarityVSM.py', 'Projects/Clean/audio.py', 'Projects/Clean/Tablet.js', 'Projects/Clean/ToolbarDroppable.js', 'Projects/Clean/gui (2).py', 'Projects/Clean/InvertBinaryTree.java', 'Projects/Clean/stream.py', 'Projects/Clean/processing.py', 'Projects/Clean/admin.js', 'Projects/Clean/BinarySearch.java', 'Projects/Clean/TextArea_layout.js', 'Projects/Clean/test.py', 'Projects/Clean/products.js', 'Projects/Clean/mergeIntervals.js', 'Projects/Clean/AStarAlgorithm.java', 'Projects/Clean/HighestPowerOf2.java', 'Projects/Clean/arrayMonotonic.js', 'Projects/Clean/wsgi.py', 'Projects/Clean/script2.js', 'Projects/Clean/LoaderSpinner.tsx', 'Projects/Clean/classifiers.py', 'Projects/Clean/MergingTwoArrays.java', 'Projects/Clean/priorityQueue.js', 'Projects/Clean/TemplateBinding.js', 'Projects/Clean/DisjointSets.java', 'Projects/Clean/createStore.tsx', 'Projects/Clean/Timeline.js', 'Projects/Clean/Person.py', 'Projects/Clean/NextGreaterPermutation.java', 'Projects/Clean/_app.js', 'Projects/Clean/Tasks.js', 'Projects/Clean/PersonBucket.py', 'Projects/Clean/sliderImage.js', 'Projects/Clean/setupTests.js', 'Projects/Clean/uniqueChar.js', 'Projects/Clean/parse_packagelock.js', 'Projects/Clean/page1.py', 'Projects/Clean/Product-1.js', 'Projects/Clean/create.js', 'Projects/Clean/script10.js', 'Projects/Clean/Combinations.java', 'Projects/Clean/stack.js', 'Projects/Clean/SurfaceBase.js', 'Projects/Clean/Fibonacci.java', 'Projects/Clean/train_aux.py', 'Projects/Clean/models (2).py', 'Projects/Clean/chatgpt_python.py', 'Projects/Clean/armstrong.py', 'Projects/Clean/forms.py', 'Projects/Clean/Products-1.js', 'Projects/Clean/script11.js', 'Projects/Clean/imageSlider.js', 'Projects/Clean/apps (2).py', 'Projects/Clean/normalizeText.py', 'Projects/Clean/main111.js', 'Projects/Clean/heap_sort.py', 'Projects/Clean/mergeSortedLinkedLists.js', 'Projects/Clean/permutations.py', 'Projects/Clean/ReverseLinkedList.java', 'Projects/Clean/path.py', 'Projects/Clean/RootToLeafSum.java', 'Projects/Clean/script2 (2).js', 'Projects/Clean/Toggle.js', 'Projects/Clean/dijkstra.py', 'Projects/Clean/Toast.js', 'Projects/Clean/WagnerFisher.py', 'Projects/Clean/ensembleCharactervsDigit.py', 'Projects/Clean/triplets.js', 'Projects/Clean/serializers.py', 'Projects/Clean/utils (2).py', 'Projects/Clean/detect_car.py', 'Projects/Clean/LowestCommonAncestor.java', 'Projects/Clean/MultiplyStrings.java', 'Projects/Clean/MiddleNode.java', 'Projects/Clean/EventContext.tsx', 'Projects/Clean/auth-2.js', 'Projects/Clean/Tip.js', 'Projects/Clean/TCPClient.java', 'Projects/Clean/lasso_regression.ipynb', 'Projects/Clean/scan_third_parties.js', 'Projects/Clean/features.py', 'Projects/Clean/MileStone.py', 'Projects/Clean/Template.js', 'Projects/Clean/power_set.py', 'Projects/Clean/index (2).js', 'Projects/Clean/GeneratingSubsets.java', 'Projects/Clean/pomo.js', 'Projects/Clean/clusterAndEnsemble.py', 'Projects/Clean/Categories.js', 'Projects/Clean/CNNFromScratch.ipynb', 'Projects/Clean/page2.py', 'Projects/Clean/GroovyVulnExample1.groovy', 'Projects/Clean/TabReorderer.js', 'Projects/Clean/Title.js', 'Projects/Clean/LongestPalindromeSubstring.java', 'Projects/Clean/DequeDemo.java', 'Projects/Clean/TimeView.js', 'Projects/Clean/heap.js', 'Projects/Clean/App.tsx', 'Projects/Clean/Announcements.js', 'Projects/Clean/app.py', 'Projects/Clean/TouchAction.js', 'Projects/Clean/product.js', 'Projects/Clean/VSM.py', 'Projects/Clean/CycleInGraph.java', 'Projects/Clean/serializers (2).py', 'Projects/Clean/Vectors.py', 'Projects/Clean/__init__.py', 'Projects/Clean/gaussian_regression.ipynb', 'Projects/Clean/index-1 (2).js', 'Projects/Clean/deep_learning.ipynb', 'Projects/Clean/pascal_triangle.py', 'Projects/Clean/Symbol.js', 'Projects/Clean/suites.js', 'Projects/Clean/vid_stream.py', 'Projects/Clean/parse_gradle.js', 'Projects/Clean/carapi.py', 'Projects/Clean/script1.js', 'Projects/Clean/sort_stack_rec.py', 'Projects/Clean/reportWebVitals.js', 'Projects/Clean/LinkedListShifting.java', 'Projects/Clean/ValidIPAddresses.java', 'Projects/Clean/script.js', 'Projects/Clean/item-2.js', 'Projects/Clean/SvgContext.js', 'Projects/Clean/pattern_matching.py', 'Projects/Clean/LongestCommonSubsequence.java', 'Projects/Clean/Svg.js', 'Projects/Clean/models.py', 'Projects/Clean/random_forest.ipynb', 'Projects/Clean/Menu.tsx', 'Projects/Clean/ValidBST.java', 'Projects/Clean/pathSimilarity.py', 'Projects/Clean/ThreeLargestNumbers.java', 'Projects/Clean/scan_docker.js', 'Projects/Clean/TimingFunctions.js', 'Projects/Clean/admin.py', 'Projects/Clean/Target.js', 'Projects/Clean/auth-1.js', 'Projects/Clean/final.py', 'Projects/Clean/app (2).py', 'Projects/Clean/urls.py', 'Projects/Clean/main (4).py', 'Projects/Clean/TodosController.js', 'Projects/Clean/SignupForm.js', 'Projects/Clean/SortedArrayToBST.java', 'Projects/Clean/item.js', 'Projects/Clean/app-with-vmodel.js', 'Projects/Clean/SwapValues.java', 'Projects/Clean/page3.py', 'Projects/Clean/guitest.py', 'Projects/Clean/AdjacencyList.java', 'Projects/Clean/train.py', 'Projects/Clean/CustomComponent.tsx', 'Projects/Clean/TaskQueue.js', 'Projects/Clean/LargestRectangleArea.java', 'Projects/Clean/Tokenizer.js', 'Projects/Clean/parse_reqtext.js', 'Projects/Clean/queue.js', 'Projects/Clean/median_finder.py', 'Projects/Clean/BTInOrderTraversal.java', 'Projects/Clean/catalan.py', 'Projects/Clean/Time3D.js', 'Projects/Clean/apps.py', 'Projects/Clean/login.js', 'Projects/Clean/imageSlider.min.js', 'Projects/Clean/TableLayout.js', 'Projects/Clean/run_length_encoding.py', 'Projects/Clean/Todos.js', 'Projects/Clean/topological_sort.py', 'Projects/Clean/settings.py', 'Projects/Clean/SmallerNumbers.java', 'Projects/Clean/Tool.js', 'Projects/Clean/udp_echo_server.py', 'Projects/Clean/TimeHeader.js', 'Projects/Clean/server.js', 'Projects/Clean/FindLoop.java', 'Projects/Clean/kadane_algorithm.py', 'Projects/Clean/Text.js', 'Projects/Clean/app-with-tab-view.js', 'Projects/Clean/filter.py', 'Projects/Clean/AuthButton.tsx', 'Projects/Clean/index.js', 'Projects/Clean/detect_credentials.js', 'Projects/Clean/TextMetrics.js', 'Projects/Clean/Dots.js', 'Projects/Clean/SubTable.js', 'Projects/Clean/TaskBar.js', 'Projects/Clean/SecondSmallest.java', 'Projects/Clean/ContactUs.js', 'Projects/Clean/app-with-router.js', 'Projects/Clean/index.ts', 'Projects/Clean/get_all_dependencies.js', 'Projects/Clean/gui.py', 'Projects/Clean/Footer.js', 'Projects/Clean/scriptresults.js', 'Projects/Clean/perfect_number.py', 'Projects/Clean/udp_echo_client.py', 'Projects/Clean/DepthFirstSearchIter.java', 'Projects/Clean/Summaries.js', 'Projects/Clean/main (3).py', 'Projects/Clean/least_common_multiple.py', 'Projects/Clean/TableScroller.js', 'Projects/Clean/gray_codec.py', 'Projects/Clean/Swipe.js', 'Projects/Clean/Subscription.js', 'Projects/Clean/Time.js', 'Projects/Clean/PrimeFactorization.java', 'Projects/Clean/manage.py', 'Projects/Clean/Task.py', 'Projects/Clean/Trie.java', 'Projects/Clean/TitleBar.js', 'Projects/Clean/NQueensProblem.java', 'Projects/Clean/TextMeasurer.js', 'Projects/Clean/Tab.js', 'Projects/Clean/LoginForm.js', 'Projects/Clean/SliderContent.js', 'Projects/Clean/prefix_sum_array.py', 'Projects/Clean/destructureArrsObjs.js', 'Projects/Clean/Arrows.js', 'Projects/Clean/tests.py', 'Projects/Clean/QuickSort.java', 'Projects/Clean/test.js', 'Projects/Clean/idx_matching_value.py', 'Projects/Clean/paint.py', 'Projects/Clean/selectionSort.js', 'Projects/Clean/SortedMatrixSearch.java', 'Projects/Clean/script3 (2).js', 'Projects/Clean/MainTask.py', 'Projects/Clean/export.py', 'Projects/Clean/ToolTip.js', 'Projects/Clean/views (2).py', 'Projects/Clean/SudokuSolver.java', 'Projects/Clean/EfficientPower.java', 'Projects/Clean/TaskManager.js', 'Projects/Clean/App.css', 'Projects/Clean/LevenshteinDistance.java', 'Projects/Clean/HelloWorld.java', 'Projects/Clean/IterativeInOrderTraversal.java', 'Projects/Clean/KnapsackProblem.java', 'Projects/Clean/scan_source_code.js', 'Projects/Clean/ReactWebComponent.tsx', 'Projects/Clean/ForgotForm.js', 'Projects/Clean/script2 (3).js', 'Projects/Clean/totient.py', 'Projects/Clean/Scratch.java', 'Projects/Clean/urls (2).py', 'Projects/Clean/urls (3).py', 'Projects/Clean/SpiralTraversal.java', 'Projects/Clean/TicTacToe.js', 'Projects/Clean/Tick.js', 'Projects/Clean/script3.js', 'Projects/Clean/asgi.py', 'Projects/Clean/Server.java', 'Projects/Clean/useAsyncStore.ts', 'Projects/Clean/CountingSort.java', 'Projects/Clean/Header.js', 'Projects/Clean/utils (3).py', 'Projects/Clean/clustering.py', 'Projects/Clean/UDPServer.java', 'Projects/Clean/CategoryItem.js', 'Projects/Clean/Transaction.js', 'Projects/Clean/palindrome.py', 'Projects/Clean/createAsyncStore.tsx', 'Projects/Clean/GroovyVulnExample2.groovy', 'Projects/Clean/FirstDuplicateValue.java', 'Projects/Clean/GenerateParentheses.java', 'Projects/Clean/grouping_symbols_matching.py', 'Projects/Clean/save.py', 'Projects/Clean/mostFrequentElements.js', 'Projects/Clean/GroovyVulnExample3.groovy', 'Projects/Clean/index.tsx', 'Projects/Clean/app-with-list-view.js', 'Projects/Clean/app.js', 'Projects/Clean/IR.py', 'Projects/Clean/TreeEditDistance.py', 'Projects/Clean/parse_piplock.js', 'Projects/Clean/TCPServer.java', 'Projects/Clean/climbingStairs.js', 'Projects/Clean/Wheel.tsx', 'Projects/Clean/three_largest.py', 'Projects/Clean/BinaryTreeDiameter.java', 'Projects/Clean/BreadthFirstSearch.java', 'Projects/Clean/lru_cache.py', 'Projects/Clean/Slider.js', 'Projects/Clean/Tap.js', 'Projects/Clean/TextArea.js', 'Projects/Clean/SmallestLargerThanTarget.java', 'Projects/Clean/script (2).js', 'Projects/Clean/Product-1 - Copy.js', 'Projects/Clean/nlp.py', 'Projects/Clean/anagram.js', 'Projects/Clean/Client.java', 'Projects/Clean/auth.js', 'Projects/Clean/useStore.ts', 'Projects/Clean/main.js', 'Projects/Clean/preprocess.py', 'Projects/Clean/TED.py', 'Projects/Clean/index-1.js', 'Projects/Clean/TagKeyNav.js', 'Projects/Clean/TopMovie.js', 'Projects/Clean/script6.js', 'Projects/Clean/hubconf.py', 'Projects/Clean/Main.py', 'Projects/Clean/main (2).py', 'Projects/Clean/utils.py', 'Projects/Clean/script5.js', 'Projects/Clean/plot.py', 'Projects/Clean/tcp_echo_server.py', 'Projects/Clean/TowersOfHanoi.java', 'Projects/Clean/Table.js', 'Projects/Clean/TextItem.js', 'Projects/Clean/bubble_sorting.py', 'Projects/Clean/tcp_echo_client.py', 'Projects/Clean/sieve_of_eratosthenes.py', 'Projects/Clean/boyer_moore.py', 'Projects/Clean/NumberOfIslands.java', 'Projects/Clean/addDOMElts.js', 'Projects/Clean/SummaryRow.js', 'Projects/Clean/patching.py', 'Projects/Clean/script12.js', 'Projects/Clean/TabScrollerMenu.js', 'Projects/Clean/disarium_number.py', 'Projects/Clean/script4.js', 'Projects/Clean/Surface.js', 'Projects/Clean/register.js', 'Projects/Clean/_document.js', 'Projects/Clean/Tag.js', 'Projects/Clean/Sum.js', 'Projects/Clean/UDPClient.java', 'Projects/Clean/BSTSearch.java', 'Projects/Clean/mergeSort.js', 'Projects/Clean/ridge_regression.ipynb', 'Projects/Clean/Project.py', 'Projects/Clean/Toolable.js', 'Projects/Clean/Thumb.js', 'Projects/Dirty/41.txt', 'Projects/Dirty/28.txt', 'Projects/Dirty/60.txt', 'Projects/Dirty/57.txt', 'Projects/Dirty/34.txt', 'Projects/Dirty/72.txt', 'Projects/Dirty/102.txt', 'Projects/Dirty/32.txt', 'Projects/Dirty/12.txt', 'Projects/Dirty/73.txt', 'Projects/Dirty/58.txt', 'Projects/Dirty/8.txt', 'Projects/Dirty/3.txt', 'Projects/Dirty/25.txt', 'Projects/Dirty/92.txt', 'Projects/Dirty/82.txt', 'Projects/Dirty/99.txt', 'Projects/Dirty/54.txt', 'Projects/Dirty/59.txt', 'Projects/Dirty/89.txt', 'Projects/Dirty/39.txt', 'Projects/Dirty/105.txt', 'Projects/Dirty/70.txt', 'Projects/Dirty/1.txt', 'Projects/Dirty/18.txt', 'Projects/Dirty/.DS_Store', 'Projects/Dirty/47.txt', 'Projects/Dirty/69.txt', 'Projects/Dirty/27.txt', 'Projects/Dirty/52.txt', 'Projects/Dirty/29.txt', 'Projects/Dirty/67.txt', 'Projects/Dirty/21.txt', 'Projects/Dirty/90.txt', 'Projects/Dirty/96.txt', 'Projects/Dirty/30.txt', 'Projects/Dirty/23.txt', 'Projects/Dirty/38.txt', 'Projects/Dirty/22.txt', 'Projects/Dirty/48.txt', 'Projects/Dirty/14.txt', 'Projects/Dirty/7.txt', 'Projects/Dirty/77.txt', 'Projects/Dirty/46.txt', 'Projects/Dirty/35.txt', 'Projects/Dirty/88.txt', 'Projects/Dirty/4.txt', 'Projects/Dirty/74.txt', 'Projects/Dirty/45.txt', 'Projects/Dirty/6.txt', 'Projects/Dirty/33.txt', 'Projects/Dirty/65.txt', 'Projects/Dirty/10.txt', 'Projects/Dirty/31.txt', 'Projects/Dirty/83.txt', 'Projects/Dirty/78.txt', 'Projects/Dirty/26.txt', 'Projects/Dirty/43.txt', 'Projects/Dirty/87.txt', 'Projects/Dirty/93.txt', 'Projects/Dirty/36.txt', 'Projects/Dirty/42.txt', 'Projects/Dirty/68.txt', 'Projects/Dirty/17.txt', 'Projects/Dirty/79.txt', 'Projects/Dirty/76.txt', 'Projects/Dirty/5.txt', 'Projects/Dirty/40.txt', 'Projects/Dirty/24.txt', 'Projects/Dirty/37.txt', 'Projects/Dirty/84.txt', 'Projects/Dirty/61.txt', 'Projects/Dirty/71.txt', 'Projects/Dirty/97.txt', 'Projects/Dirty/81.txt', 'Projects/Dirty/20.txt', 'Projects/Dirty/95.txt', 'Projects/Dirty/94.txt', 'Projects/Dirty/98.txt', 'Projects/Dirty/15.txt', 'Projects/Dirty/62.txt', 'Projects/Dirty/100.txt', 'Projects/Dirty/55.txt', 'Projects/Dirty/50.txt', 'Projects/Dirty/101.txt', 'Projects/Dirty/80.txt', 'Projects/Dirty/16.txt', 'Projects/Dirty/44.txt', 'Projects/Dirty/85.txt', 'Projects/Dirty/104.txt', 'Projects/Dirty/56.txt', 'Projects/Dirty/19.txt', 'Projects/Dirty/91.txt', 'Projects/Dirty/13.txt', 'Projects/Dirty/75.txt', 'Projects/Dirty/66.txt', 'Projects/Dirty/86.txt', 'Projects/Dirty/53.txt', 'Projects/Dirty/51.txt', 'Projects/Dirty/63.txt', 'Projects/Dirty/64.txt', 'Projects/Dirty/9.txt', 'Projects/Dirty/2.txt', 'Projects/Dirty/103.txt', 'Projects/Dirty/49.txt', 'Projects/Dirty/11.txt']\n",
            "['clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'clean', 'dirty', 'dirty', 'dirty', 'dirty', 'dirty', 'dirty', 'dirty', 'dirty', 'dirty', 'dirty', 'dirty', 'dirty', 'dirty', 'dirty', 'dirty', 'dirty', 'dirty', 'dirty', 'dirty', 'dirty', 'dirty', 'dirty', 'dirty', 'dirty', 'dirty', 'dirty', 'dirty', 'dirty', 'dirty', 'dirty', 'dirty', 'dirty', 'dirty', 'dirty', 'dirty', 'dirty', 'dirty', 'dirty', 'dirty', 'dirty', 'dirty', 'dirty', 'dirty', 'dirty', 'dirty', 'dirty', 'dirty', 'dirty', 'dirty', 'dirty', 'dirty', 'dirty', 'dirty', 'dirty', 'dirty', 'dirty', 'dirty', 'dirty', 'dirty', 'dirty', 'dirty', 'dirty', 'dirty', 'dirty', 'dirty', 'dirty', 'dirty', 'dirty', 'dirty', 'dirty', 'dirty', 'dirty', 'dirty', 'dirty', 'dirty', 'dirty', 'dirty', 'dirty', 'dirty', 'dirty', 'dirty', 'dirty', 'dirty', 'dirty', 'dirty', 'dirty', 'dirty', 'dirty', 'dirty', 'dirty', 'dirty', 'dirty', 'dirty', 'dirty', 'dirty', 'dirty', 'dirty', 'dirty', 'dirty', 'dirty', 'dirty', 'dirty', 'dirty', 'dirty', 'dirty', 'dirty']\n"
          ]
        }
      ],
      "source": [
        "zip_path = \"projects.zip\"\n",
        "extract_dir = \"Projects\"\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(\".\")\n",
        "\n",
        "\n",
        "clean_dir = os.path.join(extract_dir, 'Clean')\n",
        "dirty_dir = os.path.join(extract_dir, 'Dirty')\n",
        "\n",
        "file_paths = []\n",
        "labels = []\n",
        "\n",
        "for filename in os.listdir(clean_dir):\n",
        "    file_paths.append(os.path.join(clean_dir, filename))\n",
        "    labels.append('clean')\n",
        "\n",
        "for filename in os.listdir(dirty_dir):\n",
        "    file_paths.append(os.path.join(dirty_dir, filename))\n",
        "    labels.append('dirty')\n",
        "\n",
        "print(file_paths)\n",
        "print(labels)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Preprocessing:"
      ],
      "metadata": {
        "id": "9eBBUReCbYDw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_contents = []\n",
        "for file_path in file_paths:\n",
        "    with open(file_path, 'r',errors='ignore') as file:\n",
        "        file_contents.append(file.read())\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(file_contents, labels, test_size=0.4, random_state=42)\n",
        "vectorizer = TfidfVectorizer()\n",
        "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
        "X_test_vectorized = vectorizer.transform(X_test)\n",
        "print(X_train_vectorized.shape)\n",
        "print(X_test_vectorized.shape)\n",
        "encoder = LabelEncoder()\n",
        "y_train_encoded = encoder.fit_transform(y_train)\n",
        "y_test_encoded = encoder.transform(y_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FulKyS7yaWGJ",
        "outputId": "56359f6d-c092-4dec-b05b-3bd9d0ca7be4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(273, 13081)\n",
            "(183, 13081)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transformer Model Building:\n",
        "\n"
      ],
      "metadata": {
        "id": "Q__p1cdtbdq1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadSelfAttention(layers.Layer):\n",
        "    def __init__(self, embed_dim, num_heads=8):\n",
        "        super(MultiHeadSelfAttention, self).__init__()\n",
        "        self.embed_dim = embed_dim\n",
        "        self.num_heads = num_heads\n",
        "        if embed_dim % num_heads != 0:\n",
        "            raise ValueError(\n",
        "                f\"embedding dimension = {embed_dim} should be divisible by number of heads = {num_heads}\"\n",
        "            )\n",
        "        self.projection_dim = embed_dim // num_heads\n",
        "        self.query_dense = layers.Dense(embed_dim)\n",
        "        self.key_dense = layers.Dense(embed_dim)\n",
        "        self.value_dense = layers.Dense(embed_dim)\n",
        "        self.combine_heads = layers.Dense(embed_dim)\n",
        "\n",
        "    def attention(self, query, key, value):\n",
        "        score = tf.matmul(query, key, transpose_b=True)\n",
        "        dim_key = tf.cast(tf.shape(key)[-1], tf.float32)\n",
        "        scaled_score = score / tf.math.sqrt(dim_key)\n",
        "        weights = tf.nn.softmax(scaled_score, axis=-1)\n",
        "        output = tf.matmul(weights, value)\n",
        "        return output, weights\n",
        "\n",
        "    def separate_heads(self, x, batch_size):\n",
        "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.projection_dim))\n",
        "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "\n",
        "    def call(self, inputs):\n",
        "        batch_size = tf.shape(inputs)[0]\n",
        "        query = self.query_dense(inputs)\n",
        "        key = self.key_dense(inputs)\n",
        "        value = self.value_dense(inputs)\n",
        "        query = self.separate_heads(query, batch_size)\n",
        "        key = self.separate_heads(key, batch_size)\n",
        "        value = self.separate_heads(value, batch_size)\n",
        "        attention, weights = self.attention(query, key, value)\n",
        "        attention = tf.transpose(attention, perm=[0, 2, 1, 3])\n",
        "        concat_attention = tf.reshape(attention, (batch_size, -1, self.embed_dim))\n",
        "        output = self.combine_heads(concat_attention)\n",
        "        return output\n",
        "\n",
        "class TransformerClassifier(layers.Layer):\n",
        "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
        "        super(TransformerClassifier, self).__init__()\n",
        "        self.att = MultiHeadSelfAttention(embed_dim, num_heads)\n",
        "        self.ffn = tf.keras.Sequential(\n",
        "            [layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
        "        )\n",
        "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = layers.Dropout(rate)\n",
        "        self.dropout2 = layers.Dropout(rate)\n",
        "        self.global_avg_pool = GlobalAveragePooling1D()   \n",
        "\n",
        "    def call(self, inputs, training):\n",
        "        attn_output = self.att(inputs)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(inputs + attn_output)\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        output = self.layernorm2(out1 + ffn_output)\n",
        "        output = self.global_avg_pool(output) \n",
        "        return output\n",
        "embed_dim = 16\n",
        "num_heads = 2\n",
        "ff_dim = 16\n",
        "maxlen = 13801 \n",
        "\n",
        "inputs = layers.Input(shape=(maxlen,))\n",
        "embedding_layer = layers.Embedding(input_dim=10000, output_dim=embed_dim)\n",
        "transformer_block = TransformerClassifier(embed_dim, num_heads, ff_dim)\n",
        "x = inputs\n",
        "x = embedding_layer(x)\n",
        "x = transformer_block(x)\n",
        "x = layers.Dense(20, activation=\"relu\")(x)\n",
        "x = layers.Dropout(0.1)(x)\n",
        "outputs = layers.Dense(2, activation=\"softmax\")(x)\n",
        "\n",
        "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
        "\n",
        "def train_step(x, y):\n",
        "    with tf.GradientTape() as tape:\n",
        "        logits = model(x, training=True)\n",
        "        probabilities = tf.nn.sigmoid(logits)\n",
        "        y_reshaped = tf.reshape(y, probabilities.shape)  # Reshape y to match the shape of probabilities\n",
        "        loss_value = loss_fn(y_reshaped, probabilities)\n",
        "    grads = tape.gradient(loss_value, model.trainable_weights)\n",
        "    return grads, loss_value\n",
        "\n",
        "batch_size = 2  \n",
        "accumulation_steps = 1 \n",
        "# Initialize a list to accumulate gradients\n",
        "accumulated_grads = [tf.zeros_like(w) for w in model.trainable_weights]\n",
        "\n",
        "for epoch in range(30):\n",
        "    print(f\"Start of epoch {epoch + 1}\")\n",
        "    for step, (x_batch_train, y_batch_train) in enumerate(zip(X_train_vectorized.toarray(), y_train_encoded)):\n",
        "        grads, loss_value = train_step(x_batch_train, y_batch_train)\n",
        "        accumulated_grads = [acc_grad + grad for acc_grad, grad in zip(accumulated_grads, grads)]\n",
        "        if (step + 1) % accumulation_steps == 0:\n",
        "            optimizer.apply_gradients(zip(accumulated_grads, model.trainable_weights))\n",
        "            accumulated_grads = [tf.zeros_like(w) for w in model.trainable_weights]\n",
        "\n",
        "        print(f\"Training loss (for one batch) at step {step}: {float(loss_value)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 590
        },
        "id": "nDMh8nidbiAc",
        "outputId": "4b15b3b3-872b-4fef-9ae0-210f55d1d114"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start of epoch 1\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "InternalError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-9e65d457fbaa>\u001b[0m in \u001b[0;36m<cell line: 97>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Start of epoch {epoch + 1}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_batch_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch_train\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_vectorized\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_encoded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0maccumulated_grads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0macc_grad\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mgrad\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0macc_grad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccumulated_grads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0maccumulation_steps\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-9e65d457fbaa>\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m         \u001b[0mprobabilities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0my_reshaped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobabilities\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Reshape y to match the shape of probabilities\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-9e65d457fbaa>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training)\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mattn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mattn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0mout1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayernorm1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mattn_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0mffn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mffn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mffn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mffn_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInternalError\u001b[0m: Exception encountered when calling layer 'layer_normalization' (type LayerNormalization).\n\n{{function_node __wrapped__SquaredDifference_device_/job:localhost/replica:0/task:0/device:GPU:0}} 'cuModuleGetFunction(&function, module, kernel_name)' failed with 'CUDA_ERROR_INVALID_HANDLE' [Op:SquaredDifference]\n\nCall arguments received by layer 'layer_normalization' (type LayerNormalization):\n  â€¢ inputs=tf.Tensor(shape=(13081, 13081, 16), dtype=float32)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Evaluation and Saving:\n"
      ],
      "metadata": {
        "id": "YwUfNLE8cg_4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(X_test_vectorized, y_test_encoded)\n",
        "\n",
        "print(\"Loss: \", loss)\n",
        "print(\"Accuracy: \", accuracy)\n",
        "model.save(\"model.h5\")\n",
        "\n",
        "print(\"Saved model to disk\")\n"
      ],
      "metadata": {
        "id": "a6gUzdLncf8u"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}